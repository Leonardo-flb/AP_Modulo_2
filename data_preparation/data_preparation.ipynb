{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f81ccaf3",
   "metadata": {},
   "source": [
    "Data preparation for feeding the models will be carried out in this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6939a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58f1333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_OSATS = \"../data/raw/OSATS.xlsx\"\n",
    "PATH_TRAIN = \"../data/processed/\"\n",
    "# PATH_VIDEO_ARRAY = \"../data/video_array/\"\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "039c1388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GRSDataset import GRSDataset\n",
    "\n",
    "def prepare_data_loaders(particion, path_train, path_osats):\n",
    "\n",
    "    dataset_train = GRSDataset(path_train, path_osats, transforms=None)\n",
    "\n",
    "    train_size = int(particion * len(dataset_train))\n",
    "    val_size = int(0.1 * len(dataset_train))  # 10% for validation\n",
    "    test_size = len(dataset_train) - train_size - val_size\n",
    "\n",
    "    train_data, temp_data = random_split(dataset_train, [train_size, len(dataset_train) - train_size], generator=torch.Generator().manual_seed(42))\n",
    "    val_data, test_data = random_split(temp_data, [val_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    train_dl = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_dl = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_dl = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    train_dl_all = DataLoader(train_data, batch_size=len(train_data), shuffle=True)\n",
    "    val_dl_all = DataLoader(val_data, batch_size=len(val_data), shuffle=True)\n",
    "    test_dl_all = DataLoader(test_data, batch_size=len(test_data), shuffle=True)\n",
    "\n",
    "    return train_dl, val_dl, test_dl, train_dl_all, val_dl_all, test_dl_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba36a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, val_dl, test_dl, train_dl_all, val_dl_all, test_dl_all = prepare_data_loaders(0.70, PATH_TRAIN, PATH_OSATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e833c24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "def visualize_data(path):\n",
    "    # criar uma instância do dataset\n",
    "    df = pd.read_csv(path, header=0)\n",
    "    display(df)\n",
    "\n",
    "def visualize_dataset(train_dl, test_dl, dataset_train, dataset_test):\n",
    "    print(f\"Quantidade de casos de Treino:{len(train_dl.dataset)}\")\n",
    "    print(f\"Quantidade de casos de Validação:{len(val_dl.dataset)}\")\n",
    "    print(f\"Quantidade de casos de Teste:{len(test_dl.dataset)}\")\n",
    "\n",
    "    x, y = next(iter(train_dl)) # fazer uma iteração nos loaders para ir buscar um batch de casos\n",
    "    print(f\"Shape tensor batch casos treino, input: {x.shape}, output: {y.shape}\")\n",
    "    x, y = next(iter(val_dl)) # fazer uma iteração nos loaders para ir buscar um batch de casos\n",
    "    print(f\"Shape tensor batch casos validação, input: {x.shape}, output: {y.shape}\")\n",
    "    x, y = next(iter(test_dl))\n",
    "    print(f\"Shape tensor batch casos test, input: {x.shape}, output: {y.shape}\")\n",
    "\n",
    "    print(f'Valor maximo:{torch.max(x)} Valor mínimo:{torch.min(x)}')\n",
    "    x=x.detach().numpy()\n",
    "    print(f'Valor maximo:{np.max(x)} Valor mínimo:{np.min(x)}')\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51fe1da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de casos de Treino:21\n",
      "Quantidade de casos de Validação:3\n",
      "Quantidade de casos de Teste:6\n",
      "Shape tensor batch casos treino, input: torch.Size([4, 3, 1000, 224, 224]), output: torch.Size([4])\n",
      "Shape tensor batch casos validação, input: torch.Size([3, 3, 1000, 224, 224]), output: torch.Size([3])\n",
      "Shape tensor batch casos test, input: torch.Size([4, 3, 1000, 224, 224]), output: torch.Size([4])\n",
      "Valor maximo:1.0 Valor mínimo:0.0\n",
      "Valor maximo:1.0 Valor mínimo:0.0\n",
      "tensor([1, 3, 0, 3])\n"
     ]
    }
   ],
   "source": [
    "#visualize_data(PATH_TRAIN)\n",
    "visualize_dataset(train_dl, test_dl, train_dl_all, test_dl_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb4fa227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- Train Cases -----------------------------------\n",
      "Cases: 21\n",
      "Labels (indices): ['0', '1', '2', '3']\n",
      "Class count: [13  3  4  1]\n",
      "Sum of counts: 21\n",
      "----------------------------------- Validation Cases -----------------------------------\n",
      "Cases: 3\n",
      "Labels (indices): ['0', '1', '2']\n",
      "Class count: [1 1 1]\n",
      "Sum of counts: 3\n",
      "----------------------------------- Test Cases -----------------------------------\n",
      "Cases: 6\n",
      "Labels (indices): ['0', '1', '2', '3']\n",
      "Class count: [1 1 1 3]\n",
      "Sum of counts: 6\n"
     ]
    }
   ],
   "source": [
    "def visualize_holdout_balance(dl):\n",
    "    _, labels = next(iter(dl))\n",
    "    \n",
    "    sns.set_style('whitegrid')\n",
    "    print(\"Cases:\", len(labels))\n",
    "    \n",
    "    x, y = np.unique(labels, return_counts=True)\n",
    "    \n",
    "    print(f\"Labels (indices): {[str(n) for n in x]}\")\n",
    "    print(f\"Class count: {y}\")\n",
    "    print(f\"Sum of counts: {np.sum(y)}\")\n",
    "\n",
    "print(\"----------------------------------- Train Cases -----------------------------------\")\n",
    "visualize_holdout_balance(train_dl_all)\n",
    "print(\"--------------------------------- Validation Cases ---------------------------------\")\n",
    "visualize_holdout_balance(val_dl_all)\n",
    "print(\"------------------------------------ Test Cases ------------------------------------\")\n",
    "visualize_holdout_balance(test_dl_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
