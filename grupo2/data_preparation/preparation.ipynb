{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f8792c1-0c6e-43fe-90c6-993a290a483c",
   "metadata": {},
   "source": [
    "# Data Preparation: Video Preprocessing Pipeline\n",
    "\n",
    "This notebook implements a complete preprocessing pipeline, focusing on preparing input data for models of task1 and task2\n",
    "\n",
    "## Pipeline Overview\n",
    "\n",
    "The goal is to process full-length surgical videos and convert them into compact, information-rich numpy files, each representing a single video with:\n",
    "- A sequence of 300 key frame embeddings\n",
    "- The corresponding skill label for task1 (GRS 0-3) and task2 (OSATS)\n",
    "\n",
    "## Step-by-Step\n",
    "\n",
    "1. **Load videos** from OSSDataset/videos.\n",
    "2. **Subsample frames** at 3 frames per second to reduce temporal redundancy.\n",
    "3. **Apply transformations** to each frame:\n",
    "   - Center crop\n",
    "   - Resize to 224x224\n",
    "   - Normalize\n",
    "4. **Extract CNN features** using a pretrained ResNet50.\n",
    "5. **Select 300 representative frames** using KMeans clustering on the extracted embeddings.\n",
    "6. **Export each video’s tensor and label** into a `.npy` file.\n",
    "\n",
    "This preprocessing approach aims to reduce video size while maintaining semantic diversity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf268701-5319-411f-8583-c328e1b41b43",
   "metadata": {},
   "source": [
    "### 0. Inicialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7dbb84c-f702-4657-ba0e-5db36ed79d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a74c4b7-7d0c-487a-9ece-0a710fed1bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "         for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "device = get_default_device()   \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5b133a5-3c92-490e-9ab7-49f3140c8e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and global variables \n",
    "VIDEO_FOLDER = '../../OSS_dataset/Train/videos/'\n",
    "LABELS_PATH = '../../OSS_dataset/Train/OSATS.csv'\n",
    "\n",
    "OUTPUT_FOLDER = './data_processed/'\n",
    "OUTPUT_FOLDER = './data_processed/'\n",
    "\n",
    "FPS = 3\n",
    "CROP = 896\n",
    "RESIZE = 224\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bba117c-628e-482c-b03a-011bb1d608c4",
   "metadata": {},
   "source": [
    "### 1. Collection of Videos and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "151a64e0-5f21-4b68-94a4-1427af9fcc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label_1: 314\n",
      "Label_2: 314\n"
     ]
    }
   ],
   "source": [
    "# Label collect\n",
    "labels_task_1 = {}  # video_name → int\n",
    "labels_task_2 = {}  # video_name → list[int]\n",
    "\n",
    "df_labels = pd.read_csv(LABELS_PATH, sep=';')\n",
    "df_labels.set_index('VIDEO', inplace=True)\n",
    "\n",
    "grouped = df_labels.groupby(df_labels.index)\n",
    "\n",
    "for video_name, group in grouped:\n",
    "    # Task 1: GRS\n",
    "    grs_mean = int(round(group[\"GLOBA_RATING_SCORE\"].mean()))\n",
    "    \n",
    "    # Task 2: OSATS\n",
    "    osats_cols = [\n",
    "        \"OSATS_RESPECT\", \"OSATS_MOTION\", \"OSATS_INSTRUMENT\", \"OSATS_SUTURE\",\n",
    "        \"OSATS_FLOW\", \"OSATS_KNOWLEDGE\", \"OSATS_PERFORMANCE\", \"OSATS_FINAL_QUALITY\"\n",
    "    ]\n",
    "    osats_means = [int(round(group[col].mean())) for col in osats_cols]\n",
    "    \n",
    "    labels_task_1[video_name] = grs_mean\n",
    "    labels_task_2[video_name] = osats_means\n",
    "\n",
    "print(f\"Label_1: {len(labels_task_1.keys())}\")\n",
    "print(f\"Label_2: {len(labels_task_2.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95e2f2a6-dfdc-47b2-a8a6-41a88f83a732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Videos: 314\n"
     ]
    }
   ],
   "source": [
    "# Video paths collect\n",
    "video_paths = {}\n",
    "\n",
    "for f in os.listdir(VIDEO_FOLDER):\n",
    "    if f.endswith('.mp4'):\n",
    "        name = os.path.splitext(f)[0]  # remove .mp4\n",
    "        if name in labels_task_1 and name in labels_task_2:\n",
    "            path = os.path.join(VIDEO_FOLDER, f)\n",
    "            video_paths[name] = path\n",
    "\n",
    "print(f\"Videos: {len(video_paths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e923cbe3-139c-4aeb-8c27-30286d8eba14",
   "metadata": {},
   "source": [
    "### 2. Video Sampler (3 fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "044ebcd1-ccae-4589-82f5-2c1a54821b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video Sampler\n",
    "def extract_frames(video_path, fps=FPS):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: {video_path}\")\n",
    "        return frames\n",
    "\n",
    "    video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = int(video_fps // fps)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if count % frame_interval == 0:\n",
    "            # Convert BGR (OpenCV) to RGB (PIL)\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image = Image.fromarray(frame_rgb)\n",
    "            frames.append(image)\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    cap.release()\n",
    "    return frames\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b94d7e-1756-40f1-a3a8-080741142623",
   "metadata": {},
   "source": [
    "### 3. Crop + Resize + Normalize (using imageNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "848ef386-23e4-44de-a94d-9a15bca1c57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(CROP),  \n",
    "    transforms.Resize((RESIZE, RESIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet stats because we will use a pre-trainned RESNET\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8c1a5d-5565-47e2-8880-34c1364081b7",
   "metadata": {},
   "source": [
    "### 4. Video Processing\n",
    "- Feature Extration Using Resnet50 (T, 2048)\n",
    "- K_means to collect the most relevant frames (300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e445d1bc-2daf-4d69-bdfa-241598f996ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading ResNet50\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "resnet = torch.nn.Sequential(*list(resnet.children())[:-1])  # remove FC\n",
    "resnet.to(device)\n",
    "resnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dc51442-eb4e-418f-a944-7474ca0827ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def process_video(video_path):\n",
    "    pil_frames = extract_frames(video_path, fps=FPS)\n",
    "    transformed_frames = [transform(f) for f in pil_frames]  # (N, 3, 224, 224)\n",
    "\n",
    "    features = []\n",
    "    for i in range(0, len(transformed_frames), BATCH_SIZE):\n",
    "        batch = torch.stack(transformed_frames[i:i + BATCH_SIZE]).to(device)  # (B, 3, 224, 224)\n",
    "        output = resnet(batch).squeeze(-1).squeeze(-1)  # (B, 2048)\n",
    "        features.append(output.cpu())\n",
    "\n",
    "    features = torch.cat(features, dim=0).numpy()  # (T, 2048)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=300, random_state=0).fit(features)\n",
    "    selected_indices = []\n",
    "    for center in kmeans.cluster_centers_:\n",
    "        idx = np.argmin(np.linalg.norm(features - center, axis=1))\n",
    "        selected_indices.append(idx)\n",
    "\n",
    "    selected_indices = sorted(set(selected_indices))[:300]\n",
    "    selected_features = features[selected_indices]\n",
    "\n",
    "    return selected_features.astype(np.float32)  # (300, 2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e54fea-ad4b-4379-b850-0205de07fb81",
   "metadata": {},
   "source": [
    "### 5. Saving to numpy file \n",
    "- features: (300,2048) float32\n",
    "- label_task_1: int32\n",
    "- label_task_2: (8,) int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "884e4ed9-7b0f-4047-8838-6f677d31d96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 314/314 [2:41:58<00:00, 30.95s/it]  \n"
     ]
    }
   ],
   "source": [
    "for video_name, video_path in tqdm(video_paths.items(), desc=\"Processing\"):\n",
    "    try:\n",
    "        features = process_video(video_path)\n",
    "        if features is None or features.shape != (300, 2048):\n",
    "            print(f\"Ignored: {video_name}\")\n",
    "            continue\n",
    "\n",
    "        # Caminho de saída\n",
    "        output_path = os.path.join(OUTPUT_FOLDER, f\"{video_name}.npz\")\n",
    "        \n",
    "        np.savez(\n",
    "            output_path,\n",
    "            features=features,\n",
    "            label_task_1=np.array(labels_task_1[video_name], dtype=np.int32),\n",
    "            label_task_2=np.array(labels_task_2[video_name], dtype=np.int32)\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Error {video_name}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
